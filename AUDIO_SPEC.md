# Voice WebSocket í”„ë¡œí† ì½œ ê¸°ìˆ  ë¬¸ì„œ

## ê°œìš”

ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œì˜ WebSocket í”„ë¡œí† ì½œ ëª…ì„¸ì…ë‹ˆë‹¤.  
ìŒì„± ì…ë ¥ â†’ STT â†’ LLM â†’ TTS íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

**ë™ì‘ ë°©ì‹:** Push-to-Talk (PTT)
- ì‚¬ìš©ìê°€ ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„± ë…¹ìŒ ì‹œì‘
- ë…¹ìŒ ì™„ë£Œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì„œë²„ì— ì „ì†¡ ì™„ë£Œ ì‹ í˜¸

---

## 1. ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         í´ë¼ì´ì–¸íŠ¸ (Web)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ë…¹ìŒ] ë²„íŠ¼ â†’ ë§ˆì´í¬ â†’ PCM 16kHz â†’ WebSocket ì „ì†¡               â”‚
â”‚  [ì™„ë£Œ] ë²„íŠ¼ â†’ end_of_speech ì´ë²¤íŠ¸ ì „ì†¡                          â”‚
â”‚  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ WebSocket â†’ JSON ì´ë²¤íŠ¸ â†’ ì˜¤ë””ì˜¤ ì¬ìƒ       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚ ws:// ë˜ëŠ” wss://
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            ì„œë²„ (Rails)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ì˜¤ë””ì˜¤ ìˆ˜ì‹  â†’ STT (AssemblyAI) â†’ LLM (Claude) â†’ TTS (Cartesia) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. WebSocket ì—°ê²°

**ì—”ë“œí¬ì¸íŠ¸:** `/ws`

```
ws://{host}/ws
wss://{host}/ws  (HTTPS)
```

> **Note:** Railsì—ì„œ raw WebSocketì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (Action Cableì´ ì•„ë‹˜).

---

## 3. ë©”ì‹œì§€ í”„ë¡œí† ì½œ

### 3.1 í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„

| í˜•ì‹ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| Binary | `ArrayBuffer` | PCM ì˜¤ë””ì˜¤ (16kHz, 16-bit signed LE, mono) |
| JSON | `{ type: "end_of_speech" }` | ë…¹ìŒ ì™„ë£Œ ì‹ í˜¸ |

**ì˜¤ë””ì˜¤ ì²­í¬ í¬ê¸°:** 1,600 ìƒ˜í”Œ (100ms)

### 3.2 ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸

ëª¨ë“  ì´ë²¤íŠ¸ëŠ” JSON ë¬¸ìì—´ë¡œ ì „ì†¡ë©ë‹ˆë‹¤.

---

## 4. ì´ë²¤íŠ¸ íƒ€ì…

### ê³µí†µ í•„ë“œ

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `type` | `string` | ì´ë²¤íŠ¸ íƒ€ì… |
| `ts` | `number` | íƒ€ì„ìŠ¤íƒ¬í”„ (ms, Unix epoch) |

### 4.1 í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ ì´ë²¤íŠ¸

#### `end_of_speech` - ë…¹ìŒ ì™„ë£Œ

ì‚¬ìš©ìê°€ ë…¹ìŒ ì™„ë£Œ ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ ì „ì†¡í•©ë‹ˆë‹¤.

```json
{ "type": "end_of_speech" }
```

### 4.2 ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸ ì´ë²¤íŠ¸

#### `stt_chunk` - ë¶€ë¶„ ì „ì‚¬ (ì‹¤ì‹œê°„)

```json
{ "type": "stt_chunk", "ts": 1704355200000, "transcript": "ì•ˆë…•í•˜ì„¸" }
```

#### `stt_output` - ìµœì¢… ì „ì‚¬

```json
{ "type": "stt_output", "ts": 1704355201000, "transcript": "ì•ˆë…•í•˜ì„¸ìš”." }
```

#### `llm_chunk` - LLM ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°

```json
{ "type": "llm_chunk", "ts": 1704355202000, "text": "ì•ˆë…•í•˜ì„¸ìš”!" }
```

#### `llm_end` - LLM ì‘ë‹µ ì™„ë£Œ

```json
{ "type": "llm_end", "ts": 1704355203000 }
```

#### `tts_chunk` - ìŒì„± í•©ì„± ì˜¤ë””ì˜¤

```json
{ "type": "tts_chunk", "ts": 1704355204000, "audio": "base64..." }
```

**TTS ì˜¤ë””ì˜¤ í¬ë§·:** 24kHz, 16-bit signed little-endian, mono, Base64 ì¸ì½”ë”©

#### `error` - ì—ëŸ¬

```json
{ "type": "error", "ts": 1704355205000, "message": "STT connection failed" }
```

---

## 5. ì´ë²¤íŠ¸ íë¦„ (Push-to-Talk)

```
í´ë¼ì´ì–¸íŠ¸                         ì„œë²„
    â”‚                               â”‚
    â”‚  [ë…¹ìŒ ë²„íŠ¼ í´ë¦­]               â”‚
    â”‚â”€â”€ Binary (PCM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚â”€â”€ Binary (PCM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚<â”€â”€ stt_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  (ì‹¤ì‹œê°„ í”¼ë“œë°±)
    â”‚â”€â”€ Binary (PCM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚<â”€â”€ stt_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                               â”‚
    â”‚  [ì™„ë£Œ ë²„íŠ¼ í´ë¦­]               â”‚
    â”‚â”€â”€ { type: "end_of_speech" } â”€>â”‚
    â”‚                               â”‚  STT ìµœì¢… ì²˜ë¦¬
    â”‚<â”€â”€ stt_output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                               â”‚  LLM ì²˜ë¦¬
    â”‚<â”€â”€ llm_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚<â”€â”€ llm_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚<â”€â”€ llm_end â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                               â”‚  TTS ì²˜ë¦¬
    â”‚<â”€â”€ tts_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚<â”€â”€ tts_chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                               â”‚
    â”‚  [ë‹¤ìŒ ë…¹ìŒ ë²„íŠ¼ í´ë¦­]           â”‚
    â”‚â”€â”€ Binary (PCM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚   ...                         â”‚
```

---

## 6. íƒ€ì… ì •ì˜

### TypeScript (í´ë¼ì´ì–¸íŠ¸)

```typescript
// í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„
type ClientEvent = { type: "end_of_speech" };

// ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸
type ServerEvent =
  | { type: "stt_chunk"; ts: number; transcript: string }
  | { type: "stt_output"; ts: number; transcript: string }
  | { type: "llm_chunk"; ts: number; text: string }
  | { type: "llm_end"; ts: number }
  | { type: "tts_chunk"; ts: number; audio: string }
  | { type: "error"; ts: number; message: string };
```

### Ruby (ì„œë²„)

```ruby
def emit(type, **data)
  { type: type, ts: (Time.now.to_f * 1000).to_i, **data }
end
```

---

## 7. í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ ê°€ì´ë“œ

### 7.1 ì˜¤ë””ì˜¤ ìº¡ì²˜ (ë§ˆì´í¬ â†’ PCM 16kHz)

```typescript
const workletCode = `
class PCMProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.buffer = [];
    this.resampleRatio = sampleRate / 16000;
    this.resampleIndex = 0;
  }

  process(inputs) {
    const input = inputs[0]?.[0];
    if (!input) return true;

    for (let i = 0; i < input.length; i++) {
      this.resampleIndex += 1;
      if (this.resampleIndex >= this.resampleRatio) {
        this.resampleIndex -= this.resampleRatio;
        const sample = Math.max(-1, Math.min(1, input[i]));
        const int16 = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
        this.buffer.push(int16);
      }
    }

    const CHUNK_SIZE = 1600;
    while (this.buffer.length >= CHUNK_SIZE) {
      const chunk = this.buffer.splice(0, CHUNK_SIZE);
      const int16Array = new Int16Array(chunk);
      this.port.postMessage(int16Array.buffer, [int16Array.buffer]);
    }
    return true;
  }
}
registerProcessor('pcm-processor', PCMProcessor);
`;

export function createAudioCapture() {
  let audioContext: AudioContext | null = null;
  let workletNode: AudioWorkletNode | null = null;
  let mediaStream: MediaStream | null = null;

  return {
    async start(onChunk: (data: ArrayBuffer) => void) {
      audioContext = new AudioContext();
      const blob = new Blob([workletCode], { type: 'application/javascript' });
      const url = URL.createObjectURL(blob);
      await audioContext.audioWorklet.addModule(url);
      URL.revokeObjectURL(url);

      mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true }
      });

      const source = audioContext.createMediaStreamSource(mediaStream);
      workletNode = new AudioWorkletNode(audioContext, 'pcm-processor');
      workletNode.port.onmessage = (e) => onChunk(e.data);
      source.connect(workletNode);
    },

    stop() {
      workletNode?.disconnect();
      mediaStream?.getTracks().forEach(t => t.stop());
      workletNode = null;
      mediaStream = null;
    }
  };
}
```

### 7.2 ì˜¤ë””ì˜¤ ì¬ìƒ (Base64 PCM â†’ ìŠ¤í”¼ì»¤)

```typescript
const TTS_SAMPLE_RATE = 24000;

export function createAudioPlayback() {
  let audioContext: AudioContext | null = null;
  let nextPlayTime = 0;

  return {
    play(base64: string) {
      if (!audioContext) {
        audioContext = new AudioContext({ sampleRate: TTS_SAMPLE_RATE });
      }
      if (audioContext.state === 'suspended') audioContext.resume();

      const binary = atob(base64);
      const bytes = new Uint8Array(binary.length);
      for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);

      const view = new DataView(bytes.buffer);
      const numSamples = bytes.length / 2;
      const audioBuffer = audioContext.createBuffer(1, numSamples, TTS_SAMPLE_RATE);
      const channel = audioBuffer.getChannelData(0);
      for (let i = 0; i < numSamples; i++) {
        channel[i] = view.getInt16(i * 2, true) / 32768;
      }

      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);

      if (nextPlayTime < audioContext.currentTime) nextPlayTime = audioContext.currentTime;
      source.start(nextPlayTime);
      nextPlayTime += audioBuffer.duration;
    },

    stop() { nextPlayTime = 0; }
  };
}
```

### 7.3 Push-to-Talk ì„¸ì…˜ ê´€ë¦¬

```typescript
type SessionState = 'disconnected' | 'idle' | 'recording' | 'processing';

export function createVoiceSession() {
  let ws: WebSocket | null = null;
  let state: SessionState = 'disconnected';
  const capture = createAudioCapture();
  const playback = createAudioPlayback();
  let onStateChange: ((state: SessionState) => void) | null = null;

  function setState(newState: SessionState) {
    state = newState;
    onStateChange?.(state);
  }

  return {
    connect(onEvent: (event: ServerEvent) => void, stateCallback: (state: SessionState) => void) {
      onStateChange = stateCallback;
      const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
      ws = new WebSocket(`${protocol}//${location.host}/ws`);
      ws.binaryType = 'arraybuffer';

      ws.onopen = () => setState('idle');

      ws.onmessage = (e) => {
        const event: ServerEvent = JSON.parse(e.data);
        onEvent(event);

        if (event.type === 'tts_chunk') playback.play(event.audio);
        if (event.type === 'llm_end') setState('idle');
        if (event.type === 'error') setState('idle');
      };

      ws.onerror = () => setState('disconnected');
      ws.onclose = () => setState('disconnected');
    },

    async startRecording() {
      if (state !== 'idle' || !ws || ws.readyState !== WebSocket.OPEN) return;
      
      playback.stop();
      try {
        await capture.start((chunk) => {
          if (ws?.readyState === WebSocket.OPEN) ws.send(chunk);
        });
        setState('recording');
      } catch (err) {
        console.error('Microphone access denied:', err);
      }
    },

    stopRecording() {
      if (state !== 'recording' || !ws) return;
      capture.stop();
      ws.send(JSON.stringify({ type: 'end_of_speech' }));
      setState('processing');
    },

    disconnect() {
      capture.stop();
      playback.stop();
      ws?.close();
      ws = null;
      setState('disconnected');
    },

    getState: () => state
  };
}
```

### 7.4 React ì»´í¬ë„ŒíŠ¸ ì˜ˆì‹œ

```tsx
import { useState, useRef, useEffect } from 'react';
import { createVoiceSession, type ServerEvent, type SessionState } from './voice';

export function VoiceChat() {
  const [state, setState] = useState<SessionState>('disconnected');
  const [transcript, setTranscript] = useState('');
  const [response, setResponse] = useState('');
  const sessionRef = useRef(createVoiceSession());

  useEffect(() => {
    const session = sessionRef.current;
    session.connect(
      (event) => {
        switch (event.type) {
          case 'stt_chunk': setTranscript(event.transcript); break;
          case 'stt_output': setTranscript(event.transcript); setResponse(''); break;
          case 'llm_chunk': setResponse(prev => prev + event.text); break;
          case 'error': alert(event.message); break;
        }
      },
      setState
    );
    return () => session.disconnect();
  }, []);

  const handleButton = async () => {
    const session = sessionRef.current;
    if (state === 'idle') {
      await session.startRecording();
    } else if (state === 'recording') {
      session.stopRecording();
    }
  };

  return (
    <div>
      <button onClick={handleButton} disabled={state === 'processing' || state === 'disconnected'}>
        {state === 'disconnected' && 'ì—°ê²° ì¤‘...'}
        {state === 'idle' && 'ğŸ¤ ë…¹ìŒ'}
        {state === 'recording' && 'âœ… ì™„ë£Œ'}
        {state === 'processing' && 'â³ ì²˜ë¦¬ì¤‘...'}
      </button>
      <p><strong>ë‚˜:</strong> {transcript}</p>
      <p><strong>AI:</strong> {response}</p>
    </div>
  );
}
```

---

## 8. Rails ì„œë²„ êµ¬í˜„ ê°€ì´ë“œ

### 8.1 Gemfile

```ruby
gem 'faye-websocket'          # Raw WebSocket ì§€ì›
gem 'websocket-client-simple' # ì™¸ë¶€ WebSocket ì—°ê²°ìš©
gem 'anthropic'
gem 'puma'                    # Rack hijack ì§€ì› í•„ìš”
```

### 8.2 Middleware (Raw WebSocket)

Action Cable ëŒ€ì‹  `faye-websocket`ì„ ì‚¬ìš©í•˜ì—¬ raw WebSocketì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

```ruby
# lib/voice_websocket_middleware.rb
require 'faye/websocket'

class VoiceWebsocketMiddleware
  def initialize(app)
    @app = app
  end

  def call(env)
    if Faye::WebSocket.websocket?(env) && env['PATH_INFO'] == '/ws'
      ws = Faye::WebSocket.new(env)
      session = VoiceSession.new(ws)

      ws.on :open do |_|
        session.start
      end

      ws.on :message do |event|
        session.handle_message(event.data)
      end

      ws.on :close do |_|
        session.stop
      end

      ws.rack_response
    else
      @app.call(env)
    end
  end
end
```

### 8.3 VoiceSession í´ë˜ìŠ¤

```ruby
# app/services/voice_session.rb
class VoiceSession
  def initialize(ws)
    @ws = ws
    @stt = nil
    @tts = nil
    @messages = []
    @current_transcript = ''
  end

  def start
    @stt = AssemblyAIClient.new
    @tts = CartesiaClient.new

    # STT ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
    @stt.on_event do |event|
      send_event(event)
      if event[:type] == 'stt_output'
        @current_transcript = event[:transcript]
      end
    end

    # TTS ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
    @tts.on_event { |event| send_event(event) }
  end

  def handle_message(data)
    if data.is_a?(Array) || data.encoding == Encoding::BINARY
      # ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ë°ì´í„°
      @stt&.send_audio(data)
    else
      # JSON ë©”ì‹œì§€
      begin
        msg = JSON.parse(data)
        handle_end_of_speech if msg['type'] == 'end_of_speech'
      rescue JSON::ParserError
        # ë°”ì´ë„ˆë¦¬ë¡œ ì²˜ë¦¬
        @stt&.send_audio(data)
      end
    end
  end

  def stop
    @stt&.close
    @tts&.close
  end

  private

  def handle_end_of_speech
    # STTì— ê°•ì œ ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
    @stt&.force_endpoint

    # ìµœì¢… ì „ì‚¬ ëŒ€ê¸° í›„ LLM ì²˜ë¦¬
    Thread.new do
      sleep 0.5  # ìµœì¢… ì „ì‚¬ ëŒ€ê¸°
      process_llm(@current_transcript) if @current_transcript.present?
      @current_transcript = ''
    end
  end

  def process_llm(transcript)
    @messages << { role: 'user', content: transcript }
    response = ''

    client = Anthropic::Client.new
    client.messages(
      model: 'claude-3-5-haiku-20241022',
      max_tokens: 512,
      system: 'You are a helpful sandwich shop assistant. Be concise.',
      messages: @messages,
      stream: proc { |chunk|
        if chunk['type'] == 'content_block_delta'
          text = chunk.dig('delta', 'text') || ''
          response += text
          send_event(type: 'llm_chunk', text: text)
        end
      }
    )

    @messages << { role: 'assistant', content: response }
    send_event(type: 'llm_end')
    @tts&.send_text(response)
  rescue => e
    send_event(type: 'error', message: e.message)
  end

  def send_event(event)
    return unless @ws
    event = { ts: (Time.now.to_f * 1000).to_i }.merge(event)
    @ws.send(event.to_json)
  end
end
```

### 8.4 AssemblyAI í´ë¼ì´ì–¸íŠ¸ (STT)

**API ë²„ì „:** v3  
**ì—”ë“œí¬ì¸íŠ¸:** `wss://streaming.assemblyai.com/v3/ws`

```ruby
# app/services/assembly_ai_client.rb
require 'websocket-client-simple'

class AssemblyAIClient
  URL = "wss://streaming.assemblyai.com/v3/ws"

  def initialize(sample_rate: 16000)
    @callbacks = []
    @mutex = Mutex.new
    connect(sample_rate)
  end

  def send_audio(bytes)
    return unless @ws&.open?
    @ws.send(bytes, type: :binary)
  end

  # AssemblyAIì— ê°•ì œ ì—”ë“œí¬ì¸íŠ¸ ì‹ í˜¸ ì „ì†¡
  def force_endpoint
    return unless @ws&.open?
    @ws.send({ type: 'force_endpoint' }.to_json)
  end

  def on_event(&block)
    @mutex.synchronize { @callbacks << block }
  end

  def close
    @ws&.close
  end

  private

  def connect(sample_rate)
    params = URI.encode_www_form(
      sample_rate: sample_rate,
      format_turns: true
    )

    @ws = WebSocket::Client::Simple.connect(
      "#{URL}?#{params}",
      headers: { 'Authorization' => ENV['ASSEMBLYAI_API_KEY'] }
    )

    @ws.on(:message) do |msg|
      handle(JSON.parse(msg.data))
    rescue JSON::ParserError => e
      Rails.logger.error("AssemblyAI parse error: #{e}")
    end

    @ws.on(:error) { |e| Rails.logger.error("AssemblyAI error: #{e}") }
  end

  def handle(data)
    return unless data['type'] == 'Turn'

    event = if data['turn_is_formatted']
      { type: 'stt_output', transcript: data['transcript'] }
    else
      { type: 'stt_chunk', transcript: data['transcript'] }
    end

    return if event[:transcript].blank?
    @mutex.synchronize { @callbacks.each { |cb| cb.call(event) } }
  end
end
```

**AssemblyAI í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€:**

| ë©”ì‹œì§€ | ì„¤ëª… |
|--------|------|
| `{ type: "force_endpoint" }` | í˜„ì¬ ë°œí™” ê°•ì œ ì¢…ë£Œ |
| `{ type: "terminate_session" }` | ì„¸ì…˜ ì¢…ë£Œ |

### 8.5 Cartesia í´ë¼ì´ì–¸íŠ¸ (TTS)

**API ë²„ì „:** 2025-04-16  
**ëª¨ë¸:** sonic-3

```ruby
# app/services/cartesia_client.rb
require 'websocket-client-simple'

class CartesiaClient
  URL = "wss://api.cartesia.ai/tts/websocket"
  MODEL = "sonic-3"
  VOICE_ID = "f6ff7c0c-e396-40a9-a70b-f7607edb6937"
  VERSION = "2025-04-16"

  def initialize
    @callbacks = []
    @context_counter = 0
    @mutex = Mutex.new
    connect
  end

  def send_text(text)
    return unless @ws&.open? && text.present?

    @context_counter += 1
    @ws.send({
      model_id: MODEL,
      transcript: text,
      voice: { mode: 'id', id: VOICE_ID },
      context_id: "ctx_#{(Time.now.to_f * 1000).to_i}_#{@context_counter}",
      output_format: { container: 'raw', encoding: 'pcm_s16le', sample_rate: 24000 },
      language: 'ko'
    }.to_json)
  end

  def on_event(&block)
    @mutex.synchronize { @callbacks << block }
  end

  def close
    @ws&.close
  end

  private

  def connect
    params = URI.encode_www_form(
      api_key: ENV['CARTESIA_API_KEY'],
      cartesia_version: VERSION
    )
    @ws = WebSocket::Client::Simple.connect("#{URL}?#{params}")

    @ws.on(:message) do |msg|
      handle(JSON.parse(msg.data))
    rescue JSON::ParserError => e
      Rails.logger.error("Cartesia parse error: #{e}")
    end

    @ws.on(:error) { |e| Rails.logger.error("Cartesia error: #{e}") }
  end

  def handle(data)
    return unless data['data']
    @mutex.synchronize do
      @callbacks.each { |cb| cb.call(type: 'tts_chunk', audio: data['data']) }
    end
  end
end
```

### 8.6 Middleware ë“±ë¡

```ruby
# config/application.rb
require_relative '../lib/voice_websocket_middleware'

module YourApp
  class Application < Rails::Application
    config.middleware.use VoiceWebsocketMiddleware
  end
end
```

### 8.7 Puma ì„¤ì • (Rack hijack í™œì„±í™”)

```ruby
# config/puma.rb
workers 0  # WebSocketì€ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ê¶Œì¥
threads_count = ENV.fetch("RAILS_MAX_THREADS") { 5 }
threads threads_count, threads_count
```

### 8.8 í™˜ê²½ ë³€ìˆ˜

```bash
ASSEMBLYAI_API_KEY=your_key
CARTESIA_API_KEY=your_key
ANTHROPIC_API_KEY=your_key
```

---

## 9. ì˜¤ë””ì˜¤ í¬ë§· ìš”ì•½

| êµ¬ê°„ | ìƒ˜í”Œë ˆì´íŠ¸ | ë¹„íŠ¸ | ì±„ë„ | ì¸ì½”ë”© |
|------|-----------|------|------|--------|
| í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ | 16kHz | 16-bit signed | mono | raw PCM (little-endian) |
| ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸ (TTS) | 24kHz | 16-bit signed | mono | Base64(raw PCM LE) |

---

## 10. ìƒíƒœ ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ disconnected â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ WebSocket ì—°ê²°
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  ë…¹ìŒ ë²„íŠ¼   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  ì™„ë£Œ ë²„íŠ¼   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     idle     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ recording â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ processing â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       ^                                                      â”‚
       â”‚                      llm_end ìˆ˜ì‹                      â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 11. ì—ëŸ¬ ì²˜ë¦¬

### í´ë¼ì´ì–¸íŠ¸

```typescript
ws.onerror = () => {
  // ì¬ì—°ê²° ë˜ëŠ” ì‚¬ìš©ì ì•Œë¦¼
  setState('disconnected');
};

// ì„œë²„ ì—ëŸ¬ ì´ë²¤íŠ¸ ì²˜ë¦¬
if (event.type === 'error') {
  alert(event.message);
  setState('idle');
}
```

### ì„œë²„

```ruby
def process_llm(transcript)
  # ...
rescue => e
  send_event(type: 'error', message: "LLM ì²˜ë¦¬ ì‹¤íŒ¨: #{e.message}")
end
```

---

## 12. í…ŒìŠ¤íŠ¸

### WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸

```bash
# wscat ì„¤ì¹˜
npm install -g wscat

# ì—°ê²° í…ŒìŠ¤íŠ¸
wscat -c ws://localhost:3000/ws

# JSON ë©”ì‹œì§€ ì „ì†¡
> {"type":"end_of_speech"}
```

### ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ í…ŒìŠ¤íŠ¸ (Ruby)

```ruby
require 'websocket-client-simple'

ws = WebSocket::Client::Simple.connect('ws://localhost:3000/ws')

ws.on(:message) { |msg| puts msg.data }

# PCM íŒŒì¼ ì „ì†¡
File.open('test.pcm', 'rb') do |f|
  while (chunk = f.read(3200))  # 100ms chunks
    ws.send(chunk, type: :binary)
    sleep 0.1
  end
end

ws.send({ type: 'end_of_speech' }.to_json)
```
